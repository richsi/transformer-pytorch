import torch
import torch.nn as nn

class MultiHeadAttention(nn.Module):
  def __init__(self):
    super().__init__()


class SingleHeadAttention(nn.Module):
  def __init__(self):
    super().__init__()